{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import re \n",
    "import json \n",
    "import os\n",
    "import docx2txt \n",
    "import pandas as pd \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "directory_path=(\"some_Json_files\")\n",
    "\n",
    "with open(\"result.txt\",'w') as f:\n",
    "  for filename in os.listdir(directory_path):\n",
    "    filepath=(os.path.join(directory_path, filename))\n",
    "    def get_text(filepath):\n",
    "      if file_extension == '.json':\n",
    "        textfile = open(filepath,'r')\n",
    "        text = textfile.read()\n",
    "        return text\n",
    "      elif file_extension == '.txt':\n",
    "        jsonfile = open(filepath,'r')\n",
    "        text = jsonfile.read()\n",
    "        return text\n",
    "      elif file_extension == '.pdf':\n",
    "        reader = PdfReader(filepath)\n",
    "        text = reader.pages[0].extract_text()\n",
    "        return text\n",
    "      elif file_extension == '.docx':\n",
    "        text = docx2txt.process(filepath)\n",
    "        return text\n",
    "      elif file_extension == '.xlsx':\n",
    "        text = pd.read_excel(filepath)\n",
    "        return text \n",
    "      else:\n",
    "        text=print('No File Found')\n",
    "\n",
    "\n",
    "    name,file_extension =os.path.splitext(filepath)\n",
    "    text=get_text(filepath)\n",
    "    data1=word_tokenize(text)\n",
    "    changes = {\n",
    "        'HTML5': 'HTML',\n",
    "        'CSS3': 'CSS'\n",
    "    }\n",
    "    data = []\n",
    "    for word in data1:\n",
    "        try:\n",
    "            data.append(changes[word])\n",
    "        except KeyError:\n",
    "            data.append(word)\n",
    "\n",
    "    def gettoken(): \n",
    "        filtered_tokens=0\n",
    "        nonPunct = re.compile('.[A-Za-z0-9].')  \n",
    "        filtered = [w for w in data if nonPunct.match(w)] \n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))  \n",
    "        filtered_tokens = [w for w in filtered if w not in stop_words]  \n",
    "        return filtered_tokens  \n",
    "    list=[]\n",
    "    df = pd.read_csv('skill_keywords.csv')\n",
    "    filtered_tokens = gettoken()\n",
    "\n",
    "    for tokens in filtered_tokens:\n",
    "        if tokens in df.values:\n",
    "            list.append(tokens)\n",
    "\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    set1=set(list)\n",
    "\n",
    "    for i in set1:\n",
    "        list1.append(i)\n",
    "        list2.append(list.count(i))\n",
    "\n",
    "    dictt=dict(zip(list1,list2))\n",
    "    sorted_dict = {r: dictt[r] for r in sorted(dictt, key=dictt.get, reverse=True)}\n",
    "    maximum = max(sorted_dict, key=sorted_dict.get) \n",
    "\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    l3=[]\n",
    "    l4=[]\n",
    "\n",
    "    for key, value in sorted_dict.items():    \n",
    "        if value>(sorted_dict[maximum]/2):\n",
    "            l1.append(key)\n",
    "            l2.append(value)\n",
    "        else:\n",
    "            l3.append(key)\n",
    "            l4.append(value)\n",
    "    print('=> Filename',filename,'\\n',file=f)\n",
    "    print(\"Top Skills :\",file=f)\n",
    "    for i in range(len(l1)):\n",
    "      print(\"  -->\",l1[i]+' '+'(',str(l2[i]),')',file=f)\n",
    "\n",
    "    print(\"Other Skills :\",file=f)\n",
    "    for i in range(len(l3)):\n",
    "      print(\"  -->\",l3[i]+' '+'(',str(l4[i]),')',file=f)\n",
    "\n",
    "    obj = json.loads(text)\n",
    "    access=obj['candidate']['Employer'][(len(obj['candidate']['Employer'])-1)]['projects'][0]['projectAndSkills'][0]['name'] #SegregatedExperience \n",
    "    if access==\"\":\n",
    "      print(\"NO Hot Skills Found\",'\\n\\n',file=f)\n",
    "    else:\n",
    "      print(\"Hot Skills :\", access,'\\n\\n',file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba770357253cd0f57b2852797ab558b76444ec9f8a45aef7511b46da794e2861"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
